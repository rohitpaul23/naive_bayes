{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES ALGORITHM\n",
    "\n",
    "Use the Naı̈ve Bayes algorithm for TEXT CLASSIFICATION. The dataset for this problem\n",
    "is the Amazon Digital Music review dataset and has been obtained from this website. Given a users review,\n",
    "task is to predict the ‘overall’ rating given by the reviewer. Provided with separate training and test files containing 50,000 reviews (samples)a nd 14,000 reviews respectively. A review comes from one of the five categories\n",
    "(class label). Here, class label represents ‘overall’ rating given by the user along with the ‘reviewText’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloc = './data/q1/reviews_Digital_Music/Music_Review_train.json'\n",
    "\n",
    "jsonData = [json.loads(line) for line in open(dataloc, 'r')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reviewerID',\n",
       " 'asin',\n",
       " 'reviewerName',\n",
       " 'helpful',\n",
       " 'reviewText',\n",
       " 'overall',\n",
       " 'summary',\n",
       " 'unixReviewTime',\n",
       " 'reviewTime']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonDataKeys = list(jsonData[0].keys())\n",
    "jsonDataKeys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataloc = './data/q1/reviews_Digital_Music/Music_Review_test.json'\n",
    "\n",
    "jsonTestData = [json.loads(line) for line in open(testdataloc, 'r')]\n",
    "jsonTestDataKeys = list(jsonTestData[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Require to predict 'overall' from the dataset\n",
    "\n",
    "Determine y(labels) and number of labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(jsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5]), {5: 2608, 4: 1328, 3: 571, 2: 237, 1: 256})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "y_test = []\n",
    "labelsDict = {}\n",
    "for docIndex in range(m):\n",
    "    label = int(jsonData[docIndex][jsonDataKeys[5]])\n",
    "    y.append(label)\n",
    "    y_test.append(int(jsonTestData[docIndex][jsonTestDataKeys[5]]))\n",
    "    if label in labelsDict.keys():\n",
    "        labelsDict[label] += 1\n",
    "    else:\n",
    "        labelsDict[label] = 1\n",
    "y = np.array(y)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "labels = np.unique(y)\n",
    "y = y.reshape(m,1)\n",
    "y_test = y_test.reshape(m,1)\n",
    "L = len(labels)\n",
    "labels, labelsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueWords = []\n",
    "\n",
    "for docIndex in range(m):\n",
    "    document = jsonData[docIndex][jsonDataKeys[4]]\n",
    "    wordsInDoc = re.split(r'[\\s.,()\\']', document)\n",
    "    for word in wordsInDoc:\n",
    "        if len(word) > 2 and  word.isalpha():\n",
    "            stemWord = ps.stem(word)\n",
    "            if stemWord not in uniqueWords:\n",
    "                uniqueWords.append(stemWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20149"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureSize = len(uniqueWords)\n",
    "featureSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "X_test = []\n",
    "for docIndex in range(5000):\n",
    "    docFeatures = [0 for _ in range(featureSize)]\n",
    "    docTestFeatures = [0 for _ in range(featureSize)]\n",
    "    document = jsonData[docIndex][jsonDataKeys[4]]\n",
    "    wordsInDoc = re.split(r'[\\s.,()\\']', document)\n",
    "    for word in wordsInDoc:\n",
    "        if len(word) > 2 and  word.isalpha():\n",
    "            stemWord = ps.stem(word)\n",
    "            if stemWord in uniqueWords:\n",
    "                docFeatures[uniqueWords.index(stemWord)] += 1\n",
    "    X.append(docFeatures)    \n",
    "\n",
    "    testdocument = jsonTestData[docIndex][jsonTestDataKeys[4]]\n",
    "    wordsInTestDoc = re.split(r'[\\s.,()\\']', testdocument)\n",
    "    for word in wordsInTestDoc:\n",
    "        if len(word) > 2 and  word.isalpha():\n",
    "            stemWord = ps.stem(word)\n",
    "            if stemWord in uniqueWords:\n",
    "                docTestFeatures[uniqueWords.index(stemWord)] += 1\n",
    "    X_test.append(docTestFeatures)    \n",
    "    \n",
    "X = np.array(X)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 20149), (5000, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 1, 4, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 4, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 1, 0],\n",
       "        [0, 0, 5, ..., 0, 0, 1]]),\n",
       " array([[5],\n",
       "        [4],\n",
       "        [5],\n",
       "        ...,\n",
       "        [5],\n",
       "        [5],\n",
       "        [5]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the Paramters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining phi i.e., [phi1, phi2, phi3, phi4, phi5] to predict the probability of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[256, 237, 571, 1328, 2608]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi = [0, 0, 0, 0, 0]\n",
    "for index in range(m):\n",
    "    label = y[index][0]\n",
    "    if label == 1:\n",
    "        phi[0] += 1\n",
    "    elif label == 2:\n",
    "        phi[1] += 1\n",
    "    elif label == 3:\n",
    "        phi[2] += 1\n",
    "    elif label == 4:\n",
    "        phi[3] += 1\n",
    "    elif label == 5:\n",
    "        phi[4] += 1\n",
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0512, 0.0474, 0.1142, 0.2656, 0.5216])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi = np.array(phi)\n",
    "phi = phi/m\n",
    "phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining theta to determine the conditional probability of x given y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaParaArray = []\n",
    "alpha = 1\n",
    "for j in range(n):\n",
    "    para = [alpha for _ in range(len(labels))]\n",
    "    for i in range(m):\n",
    "        para[y[i][0]-1] += X[i][j]\n",
    "    total = np.sum(para) + alpha*n\n",
    "    para /= total\n",
    "    thetaParaArray.append(para)\n",
    "\n",
    "thetaParaArray = np.array(thetaParaArray) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20149, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.array(thetaParaArray)\n",
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3384"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logphi = np.log(phi)\n",
    "y_test_pred = []\n",
    "accuracy = 0\n",
    "for j in range(m):\n",
    "    probLabels = []\n",
    "    for label in labels: \n",
    "        theta0 = theta.T[label-1]\n",
    "        X_val = X_test[j]\n",
    "        prob = []\n",
    "        for i in range(n):\n",
    "            if X_val[i]:\n",
    "                prob.append(np.log(theta0[i]))\n",
    "        sum_ = sum(prob)\n",
    "        #print('label'+str(label))\n",
    "        probLabel = sum_ + logphi[label-1]\n",
    "        #print(probLabel)\n",
    "        probLabels.append(probLabel)\n",
    "    y_real = y_test[j]\n",
    "    y_pred = probLabels.index(max(probLabels)) + 1\n",
    "    if y_real==y_pred:\n",
    "        accuracy += 1\n",
    "    #print(y_pred, y_real)\n",
    "    #print()\n",
    "    y_test_pred.append(y_pred)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the Real label of 1st test data with the predicted label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0], y_test_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.68"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy*100/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason for having such a low accuracy:\n",
    " 1. Imbalanced Data Distribution\n",
    "    With 50% of the data has label '5', Can use Oversampling technique such as SMOTE to rectify it\n",
    "\n",
    " 2. Simple Features\n",
    "    Can use feature engineering to create new feature like combining two words"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
